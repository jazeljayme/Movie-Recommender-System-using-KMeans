{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52a5290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T23:11:00.989149Z",
     "start_time": "2021-09-05T23:10:59.896465Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-40a2a124820c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, linear_kernel\n",
    "\n",
    "import seaborn as sns\n",
    "import utils\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b759223d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T23:11:08.186415Z",
     "start_time": "2021-09-05T23:11:08.156080Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'final_cleaned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2f244e8a76a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_cleaned.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final_cleaned.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('final_cleaned.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273dee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.genre.apply(lambda x: x.split(',')[0])\n",
    "genre = y.str.replace(r'\\s+', '')\n",
    "df_dummy = pd.DataFrame()\n",
    "df_dummy['genre'] = genre\n",
    "genre_df = df_dummy.genre.value_counts().reset_index()\n",
    "genre_df.rename(columns={'genre': 'count', 'index': 'genre'}, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(genre_df['genre'], genre_df['count'])\n",
    "plt.ylabel('Genre', fontsize=14)\n",
    "plt.xlabel('Counts', fontsize=14)\n",
    "plt.title('Number of Movies per Genre', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_overview'] = df['about'].apply(lambda x: utils.process_doc(x))\n",
    "df['genre'] = df_dummy['genre'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_features(row):\n",
    "    return row['cleaned_overview']+\" \"+row['genre']\n",
    "\n",
    "df[\"combined_features\"] = df.apply(combined_features, axis =1)\n",
    "df[\"combined_features\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the TFIDF to the data\n",
    "TFIDF = TfidfVectorizer(min_df=10,lowercase=True)\n",
    "tfidf = TFIDF.fit_transform(df[\"combined_features\"])\n",
    "feature_names = TFIDF.get_feature_names()\n",
    "df1 = pd.DataFrame(tfidf.toarray(), columns=TFIDF.get_feature_names())\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93aa2c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T23:13:04.781068Z",
     "start_time": "2021-09-05T23:13:04.776071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting the Number of Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6a754",
   "metadata": {},
   "source": [
    "To identify the rank, or number of components to use ideally, we want the smallest rank that minimizes the error. However, this rank may be too computationally expensive, as in this situation. We'll choose the rank by using the following method. First, calculate the frobenius norm of the dataframe and multiply it by .0001. This will be our benchmark value. Next, iterate through\n",
    "rank = 3, 4, 5, .... For each iteration, run NMF using n_components=rank and reconstruct the matrix A. Calculate the root mean square error of the original dataframe and the reconstructed matrix A_k. When the RMSE is less than the benchmark value, we will stop and use the rank and the reconstructed matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c87787e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T23:13:17.872847Z",
     "start_time": "2021-09-05T23:13:16.839617Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a825bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_all = []\n",
    "num_topics = df1.shape[1]\n",
    "for k in range(1,num_topics, 5):\n",
    "    A = df1.copy()\n",
    "    model = NMF(n_components=k, init='random', random_state=0)\n",
    "    W = model.fit_transform(A)\n",
    "    H = model.components_\n",
    "    # get the reconstructed A with dimensions k\n",
    "    A_k = W.dot(H)\n",
    "    rmse_frob = mean_squared_error(A, A_k, squared=False)\n",
    "    # getting reconstruction error (RMSE)\n",
    "    rmse_all.append(rmse_frob)\n",
    "\n",
    "    \n",
    "from scipy import interpolate\n",
    "x = np.arange(1, num_topics, 5)\n",
    "rmse = rmse_all\n",
    "\n",
    "#interpolate missing values or \"gaps\"\n",
    "xnew = np.arange(1, num_topics)\n",
    "f = interpolate.interp1d(x, rmse, fill_value=\"extrapolate\")\n",
    "rmse_new = f(xnew)\n",
    "\n",
    "len(rmse_new)    \n",
    "\n",
    "#setting the threshold \n",
    "frob_norm_A = np.linalg.norm(A, 'fro')\n",
    "threshold = frob_norm_A*0.001\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_bool = rmse_new < threshold\n",
    "best_k = np.where(rmse_bool == True)[0][0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the interpolated reconstruction error curve \n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.arange(1,num_topics,5), rmse_all, 'o-')\n",
    "\n",
    "plt.axvline(best_k, ls='--', color='g')\n",
    "plt.title('Optimal n_components for topic modeling of Movie '\n",
    "          'Overview ', fontsize=14)\n",
    "plt.ylabel('Reconstruction Error', fontsize=12)\n",
    "plt.xlabel('n_components\\n', fontsize=12)\n",
    "print(f\"Min rec_err: {min(rmse_all)} at k: {(best_k)}\", \"\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863da8dd",
   "metadata": {},
   "source": [
    "# Simple Movie Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e4a64",
   "metadata": {},
   "source": [
    "Recommendation Systems work based on the similarity between either the content or the users who access the content.\n",
    "There are several ways to measure the similarity between two items. The recommendation systems use this similarity matrix to recommend the next most similar product to the user.\n",
    "\n",
    "In this lab, we will build a machine learning algorithm that would recommend movies based on a movie overview and genre. We will use NMF to find two non-negative matrices (W, H) whose product approximates the non- negative matrix A. We will reconstruct the matrix using their dot product. This reconstructed matrix serves as a basis to the recommendation. We will the compute the Cosine Similarity from Sklearn, as the metric to compute the pairwise similarity scores between 2 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09197a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = best_k\n",
    "nmf_ = NMF(n_components=n_topics, max_iter=100).fit(tfidf)\n",
    "nmf  = nmf_.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af76bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, sigmoid_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b143e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cosine similarity is a metric used to measure how similar two items are. Mathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space. The output value ranges from 0–1.\n",
    "0 means no similarity, where as 1 means that both the items are 100% similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3303a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5966f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommended_movies(df, title, k, cosine_sim):\n",
    "    \"\"\"Return the index of the movie if found in the database, else \n",
    "    tell user to input another movie.\n",
    "    \"\"\"\n",
    "    title = title.lower()\n",
    "    if title in df.name.str.lower().unique():\n",
    "        \n",
    "        index = df[df.name.str.lower() == title].index[0]\n",
    "        similar_movies_cos = list(enumerate(cosine_sim[index]))\n",
    "        sorted_similar_movies_cos = sorted(similar_movies_cos,\n",
    "                                       key=lambda x:x[1],\n",
    "                                       reverse=True)[1:k+1]\n",
    "        \n",
    "        for movie_id, score in sorted_similar_movies_cos:\n",
    "            print(df.iloc[movie_id]['name'])\n",
    "#             print(df.iloc[movie_id]['about'])\n",
    "#             print('\\n')\n",
    "    else:\n",
    "        return \"Movie not found in the database.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"The Godfather\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Casino royale\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a524a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"X-men\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a10af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Skyfall\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"The Dark Knight\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"The Shawshank Redemption\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6905edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Sailor Moon\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Ponyo\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_liks = \"Ponyo\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"3 Idiots\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ca14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Mononoke-hime\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Harry Potter and the Sorcerer's Stone\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Finding Nemo\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Jurassic Park\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa846e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"The Wizard of Oz\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Gone Girl\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Rurôni Kenshin - Meiji kenkaku romantan\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99bdeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Spider-Man\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27885c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"Ed, Edd n Eddy\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb665e",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_likes = \"The Blue Planet\"\n",
    "get_top_recommended_movies(df, movie_user_likes, 5, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score, silhouette_score\n",
    "\n",
    "from sklearn.base import clone\n",
    "def cluster_range(X, clusterer, k_start, k_stop, actual=None):\n",
    "    ys = []\n",
    "    centers = []\n",
    "    inertias = []\n",
    "    chs = []\n",
    "    scs = []\n",
    "   \n",
    "    for k in range(k_start, k_stop+1):\n",
    "        clusterer_k = clone(clusterer)\n",
    "        clusterer_k.set_params(n_clusters=k)\n",
    "        clusterer_k.fit(X)\n",
    "        y = clusterer_k.predict(X)\n",
    "        ys.append(y)\n",
    "        centers.append(clusterer_k.cluster_centers_)\n",
    "        inertias.append(clusterer_k.inertia_)\n",
    "        chs.append(calinski_harabasz_score(X, y))\n",
    "        scs.append(silhouette_score(X, y))\n",
    "       \n",
    "    cluster_dict = {'ys': ys,\n",
    "                    'centers': centers,\n",
    "                    'inertias': inertias,\n",
    "                    'chs': chs,\n",
    "                    'scs': scs\n",
    "                   }\n",
    "\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd1887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_internal(inertias, chs, scs):\n",
    "    \"\"\"Plot internal validation values\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    ks = np.arange(2, len(inertias)+2)\n",
    "    ax.plot(ks, inertias, '-o', label='SSE')\n",
    "    ax.plot(ks, chs, '-ro', label='CH')\n",
    "    ax.set_xlabel('$k$')\n",
    "    ax.set_ylabel('SSE/CH')\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    ax2 = ax.twinx()\n",
    "    \n",
    "    ax2.plot(ks, scs, '-ko', label='Silhouette coefficient')\n",
    " \n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    plt.legend(lines+lines2, labels+labels2, bbox_to_anchor=(1.46,1))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_internal(cluster_dict['inertias'], cluster_dict['chs'], \n",
    "                cluster_dict['scs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=2, random_state=1337)\n",
    "X_new = lsa.fit_transform(df1.to_numpy())\n",
    "kmeans_ng = KMeans(n_clusters=7, random_state=1337)\n",
    "y_predict= kmeans_ng.fit_predict(X_new)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(X_new[:,0], X_new[:,1], c=y_predict)\n",
    "plt.xlabel('SV1',fontsize=14)\n",
    "plt.ylabel('SV2', fontsize=14)\n",
    "plt.savefig('Kmeans_cluster', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d970703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_label'] = y_predict\n",
    "wiki = df[['name', 'cluster_label', 'votes']].sort_values(by='cluster_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109fc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# mask2 = np.array(Image.open(\"face.png\"))\n",
    "# font_path = 'Charming-Regular.otf'\n",
    "def similar_color_func(word=None, font_size=None,\n",
    "                       position=None, orientation=None,\n",
    "                       font_path=None, random_state=None):\n",
    "    h = 40 # 0 - 360\n",
    "    s = 100 # 0 - 100\n",
    "    l = random_state.randint(30, 70) # 0 - 100\n",
    "    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n",
    "\n",
    "\n",
    "for k in range(0,7):\n",
    "    \n",
    "    df = wiki[wiki['cluster_label']==k].sort_values('votes',\n",
    "                                          ascending=False)[:120]\n",
    "\n",
    "    titles=df['name'].values\n",
    "    d = dict(zip(titles, [1]*len(titles)))\n",
    "    \n",
    "    wordcloud = WordCloud(max_font_size=30, max_words=100, min_font_size=10,\n",
    "                          background_color=\"white\",\n",
    "                        color_func=similar_color_func,\n",
    "                       ).generate_from_frequencies(d)\n",
    "    #show\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title('Cluster '+str(k), fontsize=16)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    name_fig = 'cluster'+str(k)+'.png'\n",
    "    plt.savefig(name_fig, dpi=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
